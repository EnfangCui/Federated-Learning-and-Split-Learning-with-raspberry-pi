{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 Split Mobilenet Client Side\n",
    "This code is the server part of CIFAR10 split 2D-CNN model for **multi** client and a server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = 1 # number of clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import socket\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../../models/cifar10_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "torch.manual_seed(777)\n",
    "if device ==\"cuda:0\":\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_order(start from 0): 0\n"
     ]
    }
   ],
   "source": [
    "client_order = int(input(\"client_order(start from 0): \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_traindata = 50000 // users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "indices = list(range(50000))\n",
    "\n",
    "part_tr = indices[num_traindata * client_order : num_traindata * (client_order + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10 (root=root_path, train=True, download=True, transform=transform)\n",
    "\n",
    "trainset_sub = Subset(trainset, part_tr)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset_sub, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10 (root=root_path, train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = next(iter(train_loader))\n",
    "print(x_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(train_loader)\n",
    "print(total_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov  1 14:23:31 2018\n",
    "@author: tshzzz\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def conv_dw_client(inplane,stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inplane,inplane,kernel_size = 3,groups = inplane,stride=stride,padding=1),\n",
    "        nn.BatchNorm2d(inplane),\n",
    "        nn.ReLU()  \n",
    "        )\n",
    "\n",
    "def conv_bw(inplane,outplane,kernel_size = 3,stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inplane,outplane,kernel_size = kernel_size,groups = 1,stride=stride,padding=1),\n",
    "        nn.BatchNorm2d(outplane),\n",
    "        nn.ReLU() \n",
    "        )\n",
    "\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_class=10):\n",
    "        super(MobileNet,self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(conv_bw(3,32,3,1))\n",
    "        layers.append(conv_dw_client(32,1))\n",
    "#         layers.append(conv_dw(64,128,2))\n",
    "#         layers.append(conv_dw(128,128,1))\n",
    "#         layers.append(conv_dw(128,256,2))\n",
    "#         layers.append(conv_dw(256,256,1))\n",
    "#         layers.append(conv_dw(256,512,2))\n",
    "\n",
    "#         for i in range(5):\n",
    "#             layers.append(conv_dw(512,512,1))\n",
    "#         layers.append(conv_dw(512,1024,2))\n",
    "#         layers.append(conv_dw(1024,1024,1))\n",
    "\n",
    "#         self.classifer = nn.Sequential(\n",
    "#                 nn.Dropout(0.5),\n",
    "#                 nn.Linear(1024,num_class)\n",
    "#                 )\n",
    "        self.feature = nn.Sequential(*layers)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.feature(x)\n",
    "#         out = out.mean(3).mean(2)\n",
    "#         out = out.view(-1,1024)\n",
    "#         out = self.classifer(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mobilenet_client = MobileNet().to(device)\n",
    "print(mobilenet_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# summary(mobilenet_client, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set other hyperparameters in the model\n",
    "Hyperparameters here should be same with the server side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20  # default\n",
    "lr = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(mobilenet_client.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socket initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required socket functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_msg(sock, msg):\n",
    "    # prefix each message with a 4-byte length in network byte order\n",
    "    msg = pickle.dumps(msg)\n",
    "    msg = struct.pack('>I', len(msg)) + msg\n",
    "    sock.sendall(msg)\n",
    "\n",
    "def recv_msg(sock):\n",
    "    # read message length and unpack it into an integer\n",
    "    raw_msglen = recvall(sock, 4)\n",
    "    if not raw_msglen:\n",
    "        return None\n",
    "    msglen = struct.unpack('>I', raw_msglen)[0]\n",
    "    # read the message data\n",
    "    msg =  recvall(sock, msglen)\n",
    "    msg = pickle.loads(msg)\n",
    "    return msg\n",
    "\n",
    "def recvall(sock, n):\n",
    "    # helper function to receive n bytes or return None if EOF is hit\n",
    "    data = b''\n",
    "    while len(data) < n:\n",
    "        packet = sock.recv(n - len(data))\n",
    "        if not packet:\n",
    "            return None\n",
    "        data += packet\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set host address and port number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IP address: localhost\n"
     ]
    }
   ],
   "source": [
    "host = input(\"IP address: \")\n",
    "port = 10080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SET TIMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timmer start!\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()    # store start time\n",
    "print(\"timmer start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the client socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = socket.socket()\n",
    "s.connect((host, port))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = recv_msg(s)   # get epoch\n",
    "msg = total_batch\n",
    "send_msg(s, msg)   # send total_batch of train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                                                               | 0/25 [00:00<?, ?it/s]C:\\Users\\rlaal\\anaconda3\\envs\\py36\\lib\\site-packages\\torch\\storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n",
      "Epoch 1: 100%|██████████████████████████████████████████████████████| 25/25 [00:09<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    client_weights = recv_msg(s)\n",
    "    mobilenet_client.load_state_dict(client_weights)\n",
    "    mobilenet_client.eval()\n",
    "    for i, data in enumerate(tqdm(train_loader, ncols=100, desc='Epoch '+str(e+1))):\n",
    "        x, label = data\n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = mobilenet_client(x)\n",
    "        client_output = output.clone().detach().requires_grad_(True)\n",
    "        msg = {\n",
    "            'client_output': client_output,\n",
    "            'label': label\n",
    "        }\n",
    "        send_msg(s, msg)\n",
    "        client_grad = recv_msg(s)\n",
    "        output.backward(client_grad)\n",
    "        optimizer.step()\n",
    "    send_msg(s, mobilenet_client.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkingTime of  cpu : 12.158499479293823 sec\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()  #store end time\n",
    "print(\"WorkingTime of \",device ,\": {} sec\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
